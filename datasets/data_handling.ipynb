{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T13:01:28.131428Z",
     "start_time": "2024-10-28T13:01:27.856144Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd",
   "id": "7a1a93367e341ca9",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T13:01:28.914850Z",
     "start_time": "2024-10-28T13:01:28.907451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "norm_rates_file = 'bpm_norm_rates.csv'\n",
    "data = pd.read_csv(norm_rates_file)\n",
    "\n",
    "print(data.head())"
   ],
   "id": "38fe95fa78540922",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T13:01:53.175878Z",
     "start_time": "2024-10-28T13:01:53.171869Z"
    }
   },
   "cell_type": "code",
   "source": "print(data.tail())",
   "id": "44ca0f1bedb894fb",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T11:31:09.394120Z",
     "start_time": "2024-10-14T11:31:09.390461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extracting BPM min and BPM max columns\n",
    "bpm_min = data['BPM min']\n",
    "bpm_max = data['BPM max']\n",
    "\n",
    "# Display the first few entries of each\n",
    "print(f'BPM min: {bpm_min.head()}')\n",
    "print(f'BPM max: {bpm_max.head()}')"
   ],
   "id": "ad6985677b79f91f",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Usage BPM Min and Max Values\n",
    "\n",
    "Depending on what you need these values for, there are several operations you might consider:\n",
    "\n",
    "1. Statistical Analysis: You can compute statistical values such as the average, median, standard deviation, etc., for these BPM rates.\n",
    "2. Visualizing Data: You might want to plot these BPM rates to see trends or outliers.\n",
    "python\n",
    "3. Further Data Processing: If you are preparing to use these BPM rates for machine learning or more detailed analysis, you might want to filter, normalize, or scale these values based on your requirements.\n",
    "4. Correlation Analysis: Determine if there's a correlation between the minimum and maximum BPM rates or with other variables in your dataset."
   ],
   "id": "997b4c692309aeaa"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-14T11:31:11.897552Z",
     "start_time": "2024-10-14T11:31:11.890300Z"
    }
   },
   "source": [
    "# 1. Statistical Analysis: You can compute statistical values such as the average, median, standard deviation, etc., for these BPM rates.\n",
    "\n",
    "print(\"Statistics for BPM Min:\")\n",
    "print(bpm_min.describe())\n",
    "\n",
    "print(\"\\nStatistics for BPM Max:\")\n",
    "print(bpm_max.describe())"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T11:35:16.632376Z",
     "start_time": "2024-10-14T11:35:16.278450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. Visualizing Data: You might want to plot these BPM rates to see trends or outliers.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "bpm_min.plot(title='BPM Min Rates')\n",
    "plt.subplot(1, 2, 2)\n",
    "bpm_max.plot(title='BPM Max Rates')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "1cc7e95b8a7fa8b4",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T11:36:33.101696Z",
     "start_time": "2024-10-14T11:36:33.098279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. Example: Normalize BPM rates\n",
    "bpm_min_normalized = (bpm_min - bpm_min.min()) / (bpm_min.max() - bpm_min.min())\n",
    "bpm_max_normalized = (bpm_max - bpm_max.min()) / (bpm_max.max() - bpm_max.min())\n",
    "\n",
    "print(\"Normalized BPM Min Rates:\")\n",
    "print(bpm_min_normalized.head())"
   ],
   "id": "f7f515d3eca1a7a6",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T11:37:38.028692Z",
     "start_time": "2024-10-14T11:37:38.024644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Correlation Analysis\n",
    "\n",
    "correlation = data[['BPM min', 'BPM max']].corr()\n",
    "print(\"Correlation between BPM Min and Max:\")\n",
    "print(correlation)\n"
   ],
   "id": "fceab576cddd80bf",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T15:38:16.055011Z",
     "start_time": "2024-10-19T15:38:16.042489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv('C:/Users/benz/SynologyDrive/PycharmProjects/ToxitracAI/datasets/bpm_norm_rates.csv')\n",
    "\n",
    "# Assuming 'Time Range' is in the format 'HH:MM-HH:MM'\n",
    "# Split 'Time Range' into 'start_time' and 'end_time'\n",
    "data[['start_time', 'end_time']] = data['Time Range'].str.split('-', expand=True)\n",
    "\n",
    "# Convert these new columns into datetime format\n",
    "data['start_time'] = pd.to_datetime(data['start_time'], format='%H:%M').dt.time\n",
    "data['end_time'] = pd.to_datetime(data['end_time'], format='%H:%M').dt.time\n",
    "\n",
    "# Now you can work with these datetime objects\n",
    "print(data[['start_time', 'end_time']].head())\n"
   ],
   "id": "17495c3dcb736d69",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T13:37:19.175145Z",
     "start_time": "2024-11-18T13:37:19.163382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import pywt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from joblib import dump\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv('C:/Users/benz/SynologyDrive/PycharmProjects/ToxitracAI/datasets/bpm_norm_rates.csv')\n",
    "\n",
    "def map_condition(condition):\n",
    "    \"\"\"A function that map different conditions to normal or active\"\"\"\n",
    "    if condition in ['normal', 'resting']:\n",
    "        return 'normal'\n",
    "    else:\n",
    "        return 'active'\n",
    "\n",
    "data['Category'] = data['Condition'].apply(map_condition)\n",
    "label_encoder = LabelEncoder()\n",
    "data['Category'] = label_encoder.fit_transform(data['Category'])\n",
    "\n",
    "data['Date'] = pd.to_datetime(data['Date'], format='%Y-%m-%d')\n",
    "data['Year'] = data['Date'].dt.year\n",
    "data['Month'] = data['Date'].dt.month\n",
    "data['Day'] = data['Date'].dt.day\n",
    "\n",
    "# Process Time Range into datetime\n",
    "data[['start_time', 'end_time']] = data['Time Range'].str.split('-', expand=True)\n",
    "data['start_time'] = pd.to_datetime(data['start_time'], format='%H:%M')\n",
    "data['end_time'] = pd.to_datetime(data['end_time'], format='%H:%M')\n",
    "data['duration_hours'] = (data['end_time'] - data['start_time']).dt.seconds / 3600\n",
    "\n",
    "# Convert BPM values to numerics and normalize\n",
    "data['BPM min'] = pd.to_numeric(data['BPM min'], errors='coerce')\n",
    "data['BPM max'] = pd.to_numeric(data['BPM max'], errors='coerce')\n",
    "scaler = StandardScaler()\n",
    "data[['BPM min', 'BPM max']] = scaler.fit_transform(data[['BPM min', 'BPM max']])"
   ],
   "id": "8bc1da88ac02fbf7",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T13:37:22.030691Z",
     "start_time": "2024-11-18T13:37:22.025190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First, ensure 'BPM min' and 'BPM max' do not contain NaNs for DWT transformation\n",
    "mask = data['BPM min'].notna() & data['BPM max'].notna()\n",
    "print(f'Display mask data:\\n{mask.head()}')\n",
    "data_filtered = data[mask]\n",
    "print(f'Display filtered data:\\n{data_filtered.head()}')\n"
   ],
   "id": "eba576064f2a6227",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T13:38:13.364323Z",
     "start_time": "2024-11-18T13:38:13.309305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Recalculate DWT features on filtered data\n",
    "cA_min, _ = pywt.dwt(data_filtered['BPM min'].values, 'db1')\n",
    "cA_max, _ = pywt.dwt(data_filtered['BPM max'].values, 'db1')\n",
    "\n",
    "data_filtered = data_filtered.iloc[:len(cA_min)]  # Adjust the dataframe to match the DWT output length\n",
    "\n",
    "# Ensure that the number of samples in your features and labels are identical\n",
    "# Now prepare your feature set\n",
    "X_filtered = data_filtered[['BPM min', 'BPM max']]\n",
    "X_stacked = np.column_stack((X_filtered, cA_min, cA_max))\n",
    "y_filtered = data_filtered['Category']\n",
    "\n",
    "# Now, X_stacked and y_filtered can be used for splitting into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_stacked, y_filtered, test_size=0.4, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_test, y_test))  # Score method measures the accuracy of the model predictions"
   ],
   "id": "85d938f1be28c377",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T13:38:37.046903Z",
     "start_time": "2024-11-18T13:38:37.041092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Predict probabilities on the test set\n",
    "prob_predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate the log loss\n",
    "loss = log_loss(y_test, prob_predictions)\n",
    "print(loss)"
   ],
   "id": "1f03fb5edc12056d",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "8adaf5bf92329435",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
