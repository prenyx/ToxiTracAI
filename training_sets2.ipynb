{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training with 200 datasets"
   ],
   "metadata": {
    "id": "5c9fWZ7V5HWu"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K0jlTDfz41cj",
    "outputId": "e0816320-3f77-4b07-b5cc-f90adb6818e4"
   },
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from joblib import dump\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "def map_condition(condition):\n",
    "    return 0 if condition in ['normal', 'resting'] else 1\n",
    "\n",
    "\n",
    "# Load and prepare data\n",
    "data = pd.read_csv('bpm_norm_rates200.csv')\n",
    "data['Category'] = data['Condition'].apply(map_condition)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data[['BPM min', 'BPM max']])\n",
    "y = tf.keras.utils.to_categorical(data['Category'])\n",
    "\n",
    "# Save the scaler to a file\n",
    "# dump(scaler, 'scaler_nn_model.joblib')\n",
    "# print('Scaler saved successfully into \"scaler_nn_model.joblib\"')\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Define EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Neural Network Model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_dim=X_train.shape[1]),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model with EarlyStopping\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Save your model\n",
    "# keras.saving.save_model(model, 'heart_nn_normalrate_model.keras')\n",
    "# model.save('heart_nn_normalrate_model.h5')\n",
    "# print('heart_nn_normalrate_model.keras')\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test_labels, y_pred_labels))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Test Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Test Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gsrEfTkh5cxG",
    "outputId": "54aa0044-c710-4c4c-af9d-4254207c6f21"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load and prepare data\n",
    "data = pd.read_csv('bpm_norm_rates200.csv')\n",
    "data['Category'] = data['Condition'].apply(map_condition)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data[['BPM min', 'BPM max']])\n",
    "y = tf.keras.utils.to_categorical(data['Category'])\n",
    "\n",
    "# Save the scaler to a file\n",
    "# dump(scaler, 'scaler_nn_model.joblib')\n",
    "# print('Scaler saved successfully into \"scaler_nn_model.joblib\"')\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "# Define EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Neural Network Model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_dim=X_train.shape[1]),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model with EarlyStopping\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Save your model\n",
    "# keras.saving.save_model(model, 'heart_nn_normalrate_model.keras')\n",
    "# model.save('heart_nn_normalrate_model.h5')\n",
    "# print('heart_nn_normalrate_model.keras')\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test_labels, y_pred_labels))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5B97MQz95de0",
    "outputId": "390cc426-4c6c-4d86-8559-762deb80fc79"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Test Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Test Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_sDXPx8D56pS",
    "outputId": "ddcc7309-49bc-4afb-8307-08b2e2a62d80"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "However, without shuffling during epochs, there is a slightly higher chance that the model is exposed to patterns sequentially, which can sometimes lead to overfitting or less generalization."
   ],
   "metadata": {
    "id": "kP-1uieZALE9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Load and prepare data\n",
    "data = pd.read_csv('bpm_norm_rates200.csv')\n",
    "data['Category'] = data['Condition'].apply(map_condition)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data[['BPM min', 'BPM max']])\n",
    "y = tf.keras.utils.to_categorical(data['Category'])\n",
    "\n",
    "# Save the scaler to a file\n",
    "# dump(scaler, 'scaler_nn_model.joblib')\n",
    "# print('Scaler saved successfully into \"scaler_nn_model.joblib\"')\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "# Define EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Neural Network Model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_dim=X_train.shape[1]),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model with EarlyStopping\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=150,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Save your model\n",
    "# keras.saving.save_model(model, 'heart_nn_normalrate_model.keras')\n",
    "# model.save('heart_nn_normalrate_model.h5')\n",
    "# print('heart_nn_normalrate_model.keras')\n",
    "\n",
    "# Predictions (Evaluate Model)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test_labels, y_pred_labels))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3KddXpin57rq",
    "outputId": "842df052-515e-4f53-9943-07c98c00d87e"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Test Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Test Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AMyMquLC6G0Z",
    "outputId": "5dc69165-2f9d-4b47-a70a-85e1703555aa"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "shuffled at the epoch level, we observe that the training and testing accuracy align closely and improve steadily, showing high accuracy with consistent results across epochs. This approach reduces potential bias and ensures the model generalizes well across different parts of the data in each epoch."
   ],
   "metadata": {
    "id": "166Ekxv4AYN2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Load and prepare data\n",
    "data = pd.read_csv('bpm_norm_rates200.csv')\n",
    "data['Category'] = data['Condition'].apply(map_condition)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data[['BPM min', 'BPM max']])\n",
    "y = tf.keras.utils.to_categorical(data['Category'])\n",
    "\n",
    "# Save the scaler to a file\n",
    "# dump(scaler, 'scaler_nn_model.joblib')\n",
    "# print('Scaler saved successfully into \"scaler_nn_model.joblib\"')\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "# Define EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Neural Network Model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_dim=X_train.shape[1]),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model with EarlyStopping\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=150,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Save your model\n",
    "# keras.saving.save_model(model, 'heart_nn_normalrate_model.keras')\n",
    "# model.save('heart_nn_normalrate_model.h5')\n",
    "# print('heart_nn_normalrate_model.keras')\n",
    "\n",
    "# Predictions (Evaluate Model)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test_labels, y_pred_labels))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MXAlM_ZQ6U-b",
    "outputId": "50a14580-3adc-4ed4-c09e-43aef07d15b0"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Test Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Test Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OHnC87Wc8IQV",
    "outputId": "19362726-9c45-45e4-da08-5617a0c029fc"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load and prepare data\n",
    "data = pd.read_csv('bpm_norm_rates200.csv')\n",
    "data['Category'] = data['Condition'].apply(map_condition)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data[['BPM min', 'BPM max']])\n",
    "y = tf.keras.utils.to_categorical(data['Category'])\n",
    "\n",
    "# Save the scaler to a file\n",
    "# dump(scaler, 'scaler_nn_model.joblib')\n",
    "# print('Scaler saved successfully into \"scaler_nn_model.joblib\"')\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42, shuffle=True)\n",
    "\n",
    "# Define EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Neural Network Model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_dim=X_train.shape[1]),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model with EarlyStopping\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=150,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Save your model\n",
    "# keras.saving.save_model(model, 'heart_nn_normalrate_model.keras')\n",
    "# model.save('heart_nn_normalrate_model.h5')\n",
    "# print('heart_nn_normalrate_model.keras')\n",
    "\n",
    "# Predictions (Evaluate Model)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test_labels, y_pred_labels))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eT9bqtsa9zqR",
    "outputId": "e430f013-980f-4371-c9b0-72e9247cc91d"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Use Sigmoid\n",
    "\n"
   ],
   "metadata": {
    "id": "IMxcnxLD8TTZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Load and prepare data\n",
    "data = pd.read_csv('bpm_norm_rates200.csv')\n",
    "data['Category'] = data['Condition'].apply(map_condition)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data[['BPM min', 'BPM max']])\n",
    "y = tf.keras.utils.to_categorical(data['Category'])\n",
    "\n",
    "# Save the scaler to a file\n",
    "# dump(scaler, 'scaler_nn_model.joblib')\n",
    "# print('Scaler saved successfully into \"scaler_nn_model.joblib\"')\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Define EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Neural Network Model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='sigmoid', input_dim=X_train.shape[1]),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model with EarlyStopping\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Save your model\n",
    "# keras.saving.save_model(model, 'heart_nn_normalrate_model.keras')\n",
    "# model.save('heart_nn_normalrate_model.h5')\n",
    "# print('heart_nn_normalrate_model.keras')\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test_labels, y_pred_labels))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xRKSt9038VpO",
    "outputId": "1e8db3f9-9f47-42f6-d8b3-5d8a78434416"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load and prepare data\n",
    "data = pd.read_csv('bpm_norm_rates200.csv')\n",
    "data['Category'] = data['Condition'].apply(map_condition)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data[['BPM min', 'BPM max']])\n",
    "y = tf.keras.utils.to_categorical(data['Category'])\n",
    "\n",
    "# Save the scaler to a file\n",
    "# dump(scaler, 'scaler_nn_model.joblib')\n",
    "# print('Scaler saved successfully into \"scaler_nn_model.joblib\"')\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Define EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Neural Network Model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='sigmoid', input_dim=X_train.shape[1]),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model with EarlyStopping\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=150,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Save your model\n",
    "# keras.saving.save_model(model, 'heart_nn_normalrate_model.keras')\n",
    "# model.save('heart_nn_normalrate_model.h5')\n",
    "# print('heart_nn_normalrate_model.keras')\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test_labels, y_pred_labels))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pt5wwA-j8q29",
    "outputId": "c54c6789-f37e-406e-d1a7-1862d55b588c"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load and prepare data\n",
    "data = pd.read_csv('bpm_norm_rates200.csv')\n",
    "data['Category'] = data['Condition'].apply(map_condition)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data[['BPM min', 'BPM max']])\n",
    "y = tf.keras.utils.to_categorical(data['Category'])\n",
    "\n",
    "# Save the scaler to a file\n",
    "# dump(scaler, 'scaler_nn_model.joblib')\n",
    "# print('Scaler saved successfully into \"scaler_nn_model.joblib\"')\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Define EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Neural Network Model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='sigmoid', input_dim=X_train.shape[1]),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model with EarlyStopping\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=150,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Save your model\n",
    "# keras.saving.save_model(model, 'heart_nn_normalrate_model.keras')\n",
    "# model.save('heart_nn_normalrate_model.h5')\n",
    "# print('heart_nn_normalrate_model.keras')\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test_labels, y_pred_labels))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lMNyW73o80E0",
    "outputId": "548fd9eb-cb62-40ca-cda0-960bf3a7bd37"
   },
   "execution_count": 11,
   "outputs": []
  }
 ]
}
